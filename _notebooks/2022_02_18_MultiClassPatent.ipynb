{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2022-02-18-MultiClassPatent.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Predict the Cooperative Patent Class (CPC) by means of NLP\n",
        "> The application of data science techniques in the realm of patent analysis is in rapid growth, due to the availability of large quantity of data. Such a science leverages data to create better business intelligence, as well as facilitates decision making processes. The post recommends a machine learningdriven classification of patent publications based on a predictive model trained on the text data. The paper finds that a LinearSVC achieves best results, scoring an accuracy value of 67%. \n",
        "\n",
        "- toc: true \n",
        "- badges: true\n",
        "- hide_binder_badge: true\n",
        "- comments: true\n",
        "- categories: [NLP, Multi-class text classification, Intellectual property, Patent data, Text Vectorization models, Bag of Words model, Multinomial Naive Bayes model, Multi-model selection.]"
      ],
      "metadata": {
        "id": "kaeVbC3RaFbX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import of packages\n"
      ],
      "metadata": {
        "id": "a7uhCdLm-qR9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzSdBub597v4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd # data analysis\n",
        "from io import StringIO \n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "%matplotlib inline \n",
        "sns.set(color_codes=True)\n",
        "\n",
        "## Load the data\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DSBA Patent Project /Paper /EDA & NLP /patbase_export_274777127.csv')\n",
        "\n",
        "col = ['Cooperative Patent Class', '1st Main Claim'] #we only use those two columns \n",
        "df = df[col]\n",
        "df = df.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data source of the patent-level data is PatBase, that is a product offered by MineSoft, i.e., patent solutions provider founded in 1996 offering online products and services, such as, patent research, monitoring, and analysis, as well as other intellectual property services. Moreover, the only two features needed in this prediction exercise are the Cooperative Patent Class and the text of the 1' Main Claim.  "
      ],
      "metadata": {
        "id": "PZ7A7J5Mcfwf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making CPC label\n",
        "We can see that each patent publication, i.e., each row, has multiple CPC labels. For convinience, we only use the first label in order of appearance. "
      ],
      "metadata": {
        "id": "K6QEw1uT-UQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['cpc'] = df['Cooperative Patent Class'].str.extract(r'(^.{0,1})')"
      ],
      "metadata": {
        "id": "_SBj-iD1-W9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RegEx preprocessing"
      ],
      "metadata": {
        "id": "umvpUuEl-fC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['main_claim'] = df['1st Main Claim'].str.replace('\\[EN\\]\\s1.\\s', '', regex = True) # string stripping EN\n",
        "\n",
        "df['main_claim'] = df['main_claim'].str.lower()\n",
        "\n",
        "df['main_claim'] = df['main_claim'].str.replace('\\d+', '')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAJ7t8S_-c68",
        "outputId": "bab66c9c-6e54-4410-da8d-7459fbec0c9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building word count vectors with scikit-learn"
      ],
      "metadata": {
        "id": "aW5Mla0AAm9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "85LOeua6Auwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a series to store the labels: y\n",
        "y = df['cpc']"
      ],
      "metadata": {
        "id": "yfvwd1kgAV2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['main_claim'],y,test_size=0.33,random_state=53)"
      ],
      "metadata": {
        "id": "SGEpE1BbA2lV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CountVectorizer for text classification"
      ],
      "metadata": {
        "id": "u3gKQ9SCAsWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a CountVectorizer object: count_vectorizer\n",
        "count_vectorizer = CountVectorizer(stop_words='english')\n",
        "\n",
        "# Transform the training data using only the 'text' column values: count_train \n",
        "count_train = count_vectorizer.fit_transform(X_train)\n",
        "\n",
        "# Transform the test data using only the 'text' column values: count_test \n",
        "count_test = count_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "upXi03LHAzjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TfidfVectorizer for text classification"
      ],
      "metadata": {
        "id": "71j65nrlB7YJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "Kt_8nudKB8cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a TfidfVectorizer object: tfidf_vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english',\n",
        "                                   sublinear_tf= True, \n",
        "                                   min_df=5, \n",
        "                                   ngram_range= (1,2),\n",
        "                                   norm='l2', \n",
        "                                   encoding='latin-1')\n",
        " \n",
        "# Transform the training data: tfidf_train \n",
        "tfidf_train = tfidf_vectorizer.fit_transform(X_train)\n",
        " \n",
        "# Transform the test data: tfidf_test \n",
        "tfidf_test = tfidf_vectorizer.transform(X_test)"
      ],
      "metadata": {
        "id": "zG7ECuXuCAnD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Bayes: Text classification model"
      ],
      "metadata": {
        "id": "re-J5qMPCPmp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and testing the labelling model with CountVectorizer"
      ],
      "metadata": {
        "id": "a5i9Jg8tCqOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "\n",
        "# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\n",
        "nb_classifier = MultinomialNB(alpha = 2.6)\n",
        " \n",
        "# Fit the classifier to the training data\n",
        "nb_classifier.fit(count_train, y_train)\n",
        " \n",
        "# Create the predicted tags: pred\n",
        "predct = nb_classifier.predict(count_test)"
      ],
      "metadata": {
        "id": "2TcyWT37C0_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy score: score\n",
        "score = metrics.accuracy_score(y_test,predct)\n",
        "print(score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukKywYjBDH39",
        "outputId": "af144a7b-9623-41a7-9aa6-5c62e92da48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6304475278483487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training and testing the labelling model with TfidfVectorizer"
      ],
      "metadata": {
        "id": "cL8-MsOXElPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nb_classifier = MultinomialNB()\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "nb_classifier.fit(tfidf_train, y_train)\n",
        " \n",
        "# Create the predicted tags: pred\n",
        "predtf = nb_classifier.predict(tfidf_test)"
      ],
      "metadata": {
        "id": "Dka0rDvjFmal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the accuracy score: score\n",
        "score = metrics.accuracy_score(y_test,predtf)\n",
        "print(score)"
      ],
      "metadata": {
        "id": "rtCExVWXGCiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Attempts at improving the model"
      ],
      "metadata": {
        "id": "Rad6Ls-rKWVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Experimenting with different alphas parameters for the Multinomial Naive Bayes model."
      ],
      "metadata": {
        "id": "oD3S33mrbMJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create the list of alphas: alphas\n",
        "alphas = np.arange(2,3,0.1)\n",
        " \n",
        "# Define train_and_predict()\n",
        "def train_and_predict(alpha):\n",
        "    # Instantiate the classifier: nb_classifier\n",
        "    nb_classifier = MultinomialNB(alpha=alpha)\n",
        "    # Fit to the training data\n",
        "    nb_classifier.fit(count_train,y_train)\n",
        "    # Predict the labels: pred\n",
        "    pred = nb_classifier.predict(count_test)\n",
        "    # Compute accuracy: score\n",
        "    score = metrics.accuracy_score(y_test,pred)\n",
        "    return score\n",
        " \n",
        "# Iterate over the alphas and print the corresponding score\n",
        "for alpha in alphas:\n",
        "    print('Alpha: ', alpha)\n",
        "    print('Score: ', train_and_predict(alpha))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJk-kvdB-zFe",
        "outputId": "65caa355-4271-4582-83b2-9014a577ec49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha:  2.0\n",
            "Score:  0.6294703928082861\n",
            "\n",
            "Alpha:  2.1\n",
            "Score:  0.6294703928082861\n",
            "\n",
            "Alpha:  2.2\n",
            "Score:  0.6296658198162987\n",
            "\n",
            "Alpha:  2.3000000000000003\n",
            "Score:  0.6302521008403361\n",
            "\n",
            "Alpha:  2.4000000000000004\n",
            "Score:  0.6306429548563611\n",
            "\n",
            "Alpha:  2.5000000000000004\n",
            "Score:  0.6306429548563611\n",
            "\n",
            "Alpha:  2.6000000000000005\n",
            "Score:  0.6304475278483487\n",
            "\n",
            "Alpha:  2.7000000000000006\n",
            "Score:  0.6294703928082861\n",
            "\n",
            "Alpha:  2.8000000000000007\n",
            "Score:  0.6300566738323237\n",
            "\n",
            "Alpha:  2.900000000000001\n",
            "Score:  0.6290795387922611\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inspecting count vectorizing Multinomial Naive Bayes model\n",
        "\n",
        "The result of the inspection is not clear to me. Indeed, all the classes' features are the same except for the first class."
      ],
      "metadata": {
        "id": "e2t1MBfoKpBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the class labels: class_labels\n",
        "class_labels = nb_classifier.classes_"
      ],
      "metadata": {
        "id": "Zpij_YPDKp8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the features: feature_names\n",
        "feature_names = count_vectorizer.get_feature_names()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJFP21L0Kyqx",
        "outputId": "9329822e-273d-4510-822c-80959605d3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip the feature names together with the coefficient array and sort by weights: feat_with_weights\n",
        "feat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaUXKLwRLKY4",
        "outputId": "525a75eb-bf95-4f8c-b75c-2d4c4d7527a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the first class label and the top 20 feat_with_weights entries\n",
        "print(class_labels[0], feat_with_weights[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3oODSQeM2w5",
        "outputId": "89e2b6ba-c09b-4583-900c-186e30551f19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A [(-12.073243863160105, '_n'), (-12.073243863160105, 'aabb'), (-12.073243863160105, 'aabbco'), (-12.073243863160105, 'aabbs'), (-12.073243863160105, 'aacmm'), (-12.073243863160105, 'aad'), (-12.073243863160105, 'abandon'), (-12.073243863160105, 'abatement'), (-12.073243863160105, 'abbe'), (-12.073243863160105, 'aberration'), (-12.073243863160105, 'abiotically'), (-12.073243863160105, 'abl'), (-12.073243863160105, 'ablating'), (-12.073243863160105, 'ablative'), (-12.073243863160105, 'abnormalities'), (-12.073243863160105, 'abnormality'), (-12.073243863160105, 'abnormally'), (-12.073243863160105, 'abnormity'), (-12.073243863160105, 'abort'), (-12.073243863160105, 'aborted')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the second class label and the bottom 20 feat_with_weights entries\n",
        "print(class_labels[1], feat_with_weights[-20:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-TkCCLsNEWP",
        "outputId": "4a4dd2ea-72e9-488b-9050-7713399603c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "B [(-5.706773415428667, 'including'), (-5.668015405129263, 'coupled'), (-5.654878927223893, 'base'), (-5.632297322527184, 'assembly'), (-5.5704538172444815, 'extending'), (-5.516465507002063, 'anda'), (-5.513628625666863, 'position'), (-5.396160401912969, 'user'), (-5.247783826904798, 'body'), (-5.230560580921683, 'member'), (-5.103453193258515, 'device'), (-4.969921800633992, 'plurality'), (-4.92175839925537, 'surface'), (-4.863164234989317, 'having'), (-4.716325620804084, 'configured'), (-4.604730591663768, 'end'), (-4.5411557196183825, 'portion'), (-4.397233931131217, 'comprising'), (-4.065543850276079, 'said'), (-3.9583208889555124, 'second')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(class_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5DPSEBYNIc-",
        "outputId": "d4503bd4-3570-46f0-827b-9ac23fc133f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(class_labels[6], feat_with_weights[-20:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzf747kANVpT",
        "outputId": "d4bc246b-57e3-4e6b-b1d2-5da920d21e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "G [(-5.706773415428667, 'including'), (-5.668015405129263, 'coupled'), (-5.654878927223893, 'base'), (-5.632297322527184, 'assembly'), (-5.5704538172444815, 'extending'), (-5.516465507002063, 'anda'), (-5.513628625666863, 'position'), (-5.396160401912969, 'user'), (-5.247783826904798, 'body'), (-5.230560580921683, 'member'), (-5.103453193258515, 'device'), (-4.969921800633992, 'plurality'), (-4.92175839925537, 'surface'), (-4.863164234989317, 'having'), (-4.716325620804084, 'configured'), (-4.604730591663768, 'end'), (-4.5411557196183825, 'portion'), (-4.397233931131217, 'comprising'), (-4.065543850276079, 'said'), (-3.9583208889555124, 'second')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selection of various model with count vectorizing "
      ],
      "metadata": {
        "id": "F1AhGEXYPOBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "hmvWYkZRPNqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = [\n",
        "    RandomForestClassifier(n_estimators=200, max_depth=3, random_state=0),\n",
        "    LinearSVC(),\n",
        "    MultinomialNB(alpha = 2.6),\n",
        "    LogisticRegression(random_state=0),\n",
        "    ]"
      ],
      "metadata": {
        "id": "_9KlI6ovPWm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CV = 5\n",
        "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
        "\n",
        "entries = []\n",
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "  accuracies = cross_val_score(model, count_train, y_train, scoring='accuracy', cv=CV)\n",
        "  for fold_idx, accuracy in enumerate(accuracies): entries.append((model_name, fold_idx, accuracy))\n",
        "\n",
        "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
      ],
      "metadata": {
        "id": "vk0_PAC1QKTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_df.groupby('model_name').accuracy.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKrJ69PfQ1az",
        "outputId": "b386eebf-68a9-4a00-d362-103c7db5f5a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_name\n",
              "LinearSVC                 0.574743\n",
              "LogisticRegression        0.610743\n",
              "MultinomialNB             0.625468\n",
              "RandomForestClassifier    0.374146\n",
              "Name: accuracy, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Selection of various model with tfidf vectorizing "
      ],
      "metadata": {
        "id": "HCyQgNnNRZHa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CV = 5\n",
        "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
        "\n",
        "entries = []\n",
        "for model in models:\n",
        "  model_name = model.__class__.__name__\n",
        "  accuracies = cross_val_score(model, tfidf_train, y_train, scoring='accuracy', cv=CV)\n",
        "  for fold_idx, accuracy in enumerate(accuracies): entries.append((model_name, fold_idx, accuracy))\n",
        "\n",
        "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])"
      ],
      "metadata": {
        "id": "z9joqhS-RaOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_df.groupby('model_name').accuracy.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XjavMPDSEeX",
        "outputId": "c1240677-8236-46bb-b1cd-843c62cea1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "model_name\n",
              "LinearSVC                 0.674175\n",
              "LogisticRegression        0.658003\n",
              "MultinomialNB             0.547213\n",
              "RandomForestClassifier    0.374916\n",
              "Name: accuracy, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LinearSVC and Logistic Regression perform better than the other two classifiers, with LinearSVC having a slight advantage with a median accuracy of 67%. Focusing on the LinearSVC model, which has demonstrated to perform the best, I report its confusing matrix, to show the discrepancies between predicted and actual labels."
      ],
      "metadata": {
        "id": "A3A0B5Lbc8yM"
      }
    }
  ]
}